{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AfterWork Data Science: Classification Analysis with Python",
      "provenance": [],
      "collapsed_sections": [
        "BA_HMQbPHWQJ",
        "SPpfqZYzrKvs",
        "eagUqvVmeRTx",
        "Pz6qTiItChtg",
        "G8NJS6N6eU7j",
        "wBSYp3fVIupH",
        "uebT2koxr4V4",
        "B-eE6btO3KKM",
        "eiWteB6fHPmU"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kundyyy/100-Days-Of-ML-Code/blob/master/AfterWork_Data_Science_Classification_Analysis_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpeR9aETcRDP",
        "colab_type": "text"
      },
      "source": [
        "<font color=\"blue\">To use this notebook on Google Colaboratory, you will need to make a copy of it. Go to **File** > **Save a Copy in Drive**. You can then use the new copy that will appear in the new tab.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e13tRpKcJHm",
        "colab_type": "text"
      },
      "source": [
        "# AfterWork Data Science: Classification Analysis with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA_HMQbPHWQJ",
        "colab_type": "text"
      },
      "source": [
        "## Importing the Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moay-lWZm7z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will start by running this cell which will import the necessary libraries\n",
        "# ---\n",
        "# \n",
        "import pandas as pd                # Pandas for data manipulation\n",
        "import numpy as np                 # Numpy for scientific computations\n",
        "import matplotlib.pyplot as plt    # Matplotlib for visualisation - We might not use it but just incase you decide to \n",
        "%matplotlib inline                 # This line will store and show our visualisations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPpfqZYzrKvs",
        "colab_type": "text"
      },
      "source": [
        "## Example "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6pUHkWwrI8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example \n",
        "# ---\n",
        "# Question: Will John, 40 years old with a salary of 2500 will buy a car?\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/SocialNetworkAdsDataset\n",
        "# ---"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eagUqvVmeRTx",
        "colab_type": "text"
      },
      "source": [
        "#### Data Importation and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1pbsTYuPOLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading and previewing our dataset\n",
        "# ---\n",
        "# \n",
        "social_df = pd.read_csv('http://bit.ly/SocialNetworkAdsDataset')\n",
        "social_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPZkxTRrdQaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Determining the size of our dataset\n",
        "# (records, columns)\n",
        "# ---\n",
        "# \n",
        "social_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz6qTiItChtg",
        "colab_type": "text"
      },
      "source": [
        "#### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtaBMmZBCkW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normally during this stage we would perform quite a number of \n",
        "# procedures, but because our focus is only onlearning about the \n",
        "# different modeling algorithms, we will only perform once \n",
        "# essential step in ot dataset. We will perform encoding,\n",
        "# which will help us transform our categorical values in our \n",
        "# dataset into numerical values. \n",
        "# Lets see what happens when we encode the gender variable \n",
        "# to have only numerical values. \n",
        "# ---\n",
        "#\n",
        "social_df[\"Gender\"] = np.where(social_df[\"Gender\"].str.contains(\"Male\", \"Female\"), 1, 0)\n",
        "social_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8NJS6N6eU7j",
        "colab_type": "text"
      },
      "source": [
        "#### Data Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybg1VYOGSXbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing our dataset for training\n",
        "# ---\n",
        "# We first divide our data into attributes and labels:\n",
        "# You can think of this as splitting our data set in dependent and independent variables \n",
        "# where Age and EstimatedSalary are the independent variables and Purchased are the dependent/label variable.\n",
        "# ---\n",
        "# \n",
        "X = social_df.iloc[:, [1, 2 ,3]].values  # Independent/predictor variables\n",
        "y = social_df.iloc[:, 4].values          # Dependent/label variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFyZcCeVScEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into a training set and test set\n",
        "# ---\n",
        "# We will split our dataset into training data and test data. \n",
        "# Training data will be used to train our logistic model and test data will be used to validate our model\n",
        "# Because weâ€™ll use sklearn to split our data, we will import train_test_split from sklearn.model_selection\n",
        "# ---\n",
        "# \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgn73UwVS9hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Scaling / Normalisation\n",
        "# ---\n",
        "# We then perform feature scaling / normalisation to scale our data between 0 and 1 so as to get better accuracy.\n",
        "# Here, scaling is important because there is a huge difference between Age and EstimatedSalary.\n",
        "# In addition, this would also reduce redundacy in our dataset. \n",
        "# ---\n",
        "# \n",
        "\n",
        "# We import our scaler from sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# We make an instance sc_X of the object StandardScaler.\n",
        "# You can think of making an instance as making a copy.\n",
        "sc_X = StandardScaler()\n",
        "\n",
        "# We then fit and transform X_train and X_test\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cDNlsiGTaRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In this example, because we will be comparing how \n",
        "# the different classification algorithms will perform, \n",
        "# we import our classifiers as shown below.\n",
        "# ---\n",
        "#\n",
        "from sklearn.linear_model import LogisticRegression # Logistic Regression Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier     # Decision Tree Classifier\n",
        "from sklearn.svm import SVC                         # SVM Classifier\n",
        "from sklearn.naive_bayes import GaussianNB          # Naive Bayes Classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier  # KNN Classifier\n",
        "\n",
        "# Below, we make an instance classifier of the object LogisticRegression, \n",
        "# DecisionTreeClassifier, SVC, GaussianNB, KNeighborsClassifier, GaussianNB.\n",
        "# As we will get to see, each of the classifiers take different parameters.\n",
        "# ---\n",
        "# \n",
        "logistic_classifier = LogisticRegression(random_state = 0, solver='lbfgs')\n",
        "decision_classifier = DecisionTreeClassifier()\n",
        "svm_classifier = SVC()\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "naive_classifier = GaussianNB()\n",
        "\n",
        "# Now using these classifiers to fit our data, X_train and y_train.\n",
        "# By fitting we mean we train our classifiers based on the train dataset.\n",
        "# ---\n",
        "# Upon running this cell, we should have classifiers that can predict \n",
        "# whether a person will buy a car or not.\n",
        "# ---\n",
        "# Don't worry about the output, we get GaussianNB because our Naive Bayes classifier\n",
        "# is the last one to be built.\n",
        "# ---\n",
        "#\n",
        "logistic_classifier.fit(X_train, y_train)\n",
        "decision_classifier.fit(X_train, y_train)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "naive_classifier.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAx-7zU7Tyrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We now predict the test set results. \n",
        "# This will help us determine whether our classifiers made the correct predictions.\n",
        "# ---\n",
        "# No expected output here.\n",
        "# ---\n",
        "logistic_y_prediction = logistic_classifier.predict(X_test) \n",
        "decision_y_prediction = decision_classifier.predict(X_test) \n",
        "svm_y_prediction = svm_classifier.predict(X_test) \n",
        "knn_y_prediction = knn_classifier.predict(X_test) \n",
        "naive_y_prediction = naive_classifier.predict(X_test) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG_q-tVaUFxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We then import evaluation metrics to determine the accuracy of classifiers\n",
        "# ---\n",
        "# \n",
        "from sklearn.metrics import classification_report, accuracy_score \n",
        "\n",
        "# The accuracy score - is the simplest way to evaluate \n",
        "# However, we note not for a highly imbalance dataset. \n",
        "# By imbalanced we mean that our original dataset would\n",
        "# need to have an equal no's of 1 and 0's\n",
        "# ---\n",
        "print(accuracy_score(logistic_y_prediction, y_test))\n",
        "print(accuracy_score(decision_y_prediction, y_test))\n",
        "print(accuracy_score(svm_y_prediction, y_test))\n",
        "print(accuracy_score(knn_y_prediction, y_test))\n",
        "print(accuracy_score(naive_y_prediction, y_test))\n",
        "\n",
        "# From the accuracy scores we get 90%, 90%, 93%, 93% & 91% respectively.\n",
        "# The most accurate classifier being SVM & KNN. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4wgNdhhrdVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We now print the classification report, \n",
        "# which is more reliable for a highly imbalanced dataset. \n",
        "# We use the precision values which give us accuracy values.\n",
        "# \n",
        "# ---\n",
        "# The precision will be \"how many are correctly classified among that class\".\n",
        "# The recall means \"how many of this class you find over the whole number of element of this class\".\n",
        "# The f1-score is the harmonic mean between precision & recall.\n",
        "# The support is the number of occurence of the given class in your dataset.\n",
        "# ---\n",
        "# \n",
        "print('Logistic classifier:')\n",
        "print(classification_report(y_test, logistic_y_prediction))\n",
        "\n",
        "print('Decision Tree classifier:')\n",
        "print(classification_report(y_test, decision_y_prediction))\n",
        "\n",
        "print('SVM Classifier:')\n",
        "print(classification_report(y_test, svm_y_prediction))\n",
        "\n",
        "print('KNN Classifier:')\n",
        "print(classification_report(y_test, knn_y_prediction))\n",
        "\n",
        "print('Naive Bayes Classifier:')\n",
        "print(classification_report(y_test, naive_y_prediction)) \n",
        "\n",
        "# From our classification report,\n",
        "# Our support tells us that our dataset is highly imbalanced i.e. 63 0's and 32 1's.\n",
        "# From the weighted avg which takes into account of our imbalanced\n",
        "# dataset we get 90%, 90%, 93%, 93%, 91%.\n",
        "# Still, the most accurate classifiers being SVM and KNN. \n",
        "# We can then further perform model opmization techiniques i.e. \n",
        "# data cleaning, feature engineering, checking for model assumptions, etc. \n",
        "# to further get the best classifier. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnqqUOET9QLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Answering our question\n",
        "# ---\n",
        "# We then make a new prediction & compare results.\n",
        "# Note that we would only use the best optimized classifier for this case.\n",
        "# ---\n",
        "# Predict whether John, 60 years old with a salary of 2500 will buy a car or not?\n",
        "# ---\n",
        "# Dataset limitation: This is not a practical dataset, thus dataset will lack essential features/variables.\n",
        "# In a real case scenario, we would work with may kinds of datasets that require transformation\n",
        "# i.e. data cleaning, feature engineering, etc.\n",
        "# ---\n",
        "#\n",
        "new_case = [[1,\t60, 1500]]\n",
        "\n",
        "print(logistic_classifier.predict(new_case))\n",
        "print(decision_classifier.predict(new_case))\n",
        "print(\"Best Classifier SVM\", svm_classifier.predict(new_case))\n",
        "print(\"Best Classifier KNN\", knn_classifier.predict(new_case))\n",
        "print(naive_classifier.predict(new_case))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBSYp3fVIupH",
        "colab_type": "text"
      },
      "source": [
        "##<font color=\"green\">Challenges</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uebT2koxr4V4",
        "colab_type": "text"
      },
      "source": [
        "###<font color=\"green\">Challenge 1</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVcDuh88sFLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Question: As a Reseacher at KEMRI you are performing research on diabetes.\n",
        "# Create the a classifier to determine whether a person has diabetes or not\n",
        "# from the given the following sample dataset.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/ADiabetesDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-eE6btO3KKM",
        "colab_type": "text"
      },
      "source": [
        "###<font color=\"green\">Challenge 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b-Q2CMI2wg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Question: A cancer medical reasearch institution would like to make predictions on two different \n",
        "# cancer types benign and malignant. Build a model to predict the breast cancer type \n",
        "# (0 = benign or 1 = malignant) given the following dataset. In addition, make a prediction.\n",
        "# NB: Remember to record your observations.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/BreastCancersDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiWteB6fHPmU",
        "colab_type": "text"
      },
      "source": [
        "###<font color=\"green\">Challenge 3</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOZ25wbCHQPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Challenge 3\n",
        "# ---\n",
        "# Question: Build a classifier to predict car sales and check the accuracy of the prediction.\n",
        "# given the following dataset\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/3dvU2BB\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}